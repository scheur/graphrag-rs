//! Production-ready incremental graph store implementation.
//!
//! This module provides the `IncrementalGraphStore` trait defining
//! atomic update operations, and `ProductionGraphStore` implementing
//! full ACID guarantees for graph modifications.

use crate::core::{Entity, EntityId, GraphRAGError, Relationship, Result};
#[cfg(feature = "incremental")]
use crate::core::KnowledgeGraph;
#[cfg(feature = "incremental")]
use std::time::Duration;
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;


#[cfg(feature = "incremental")]
use {
    dashmap::DashMap,
    parking_lot::RwLock,
    std::sync::Arc,
    tokio::sync::broadcast,
};

use super::change_log::{ChangeRecord, GraphDelta};
use super::conflict::ConflictStrategy;
use super::types::{ConsistencyReport, GraphStatistics, TransactionId, UpdateId};

#[cfg(feature = "incremental")]
use super::batch::BatchProcessor;
#[cfg(feature = "incremental")]
use super::cache::SelectiveInvalidation;
#[cfg(feature = "incremental")]
use super::change_log::{ChangeData, RollbackData};
#[cfg(feature = "incremental")]
use super::conflict::{Conflict, ConflictResolver, ConflictType};
#[cfg(feature = "incremental")]
use super::manager::IncrementalConfig;
#[cfg(feature = "incremental")]
use super::monitor::UpdateMonitor;
#[cfg(feature = "incremental")]
use super::pagerank::IncrementalPageRank;
#[cfg(feature = "incremental")]
use super::types::{ChangeType, Operation};

// ============================================================================
// IncrementalGraphStore Trait
// ============================================================================

/// Extended trait for incremental graph operations with production-ready features
#[async_trait::async_trait]
pub trait IncrementalGraphStore: Send + Sync {
    /// The error type for incremental graph operations
    type Error: std::error::Error + Send + Sync + 'static;

    /// Upsert an entity (insert or update)
    async fn upsert_entity(&mut self, entity: Entity) -> Result<UpdateId>;

    /// Upsert a relationship
    async fn upsert_relationship(&mut self, relationship: Relationship) -> Result<UpdateId>;

    /// Delete an entity and its relationships
    async fn delete_entity(&mut self, entity_id: &EntityId) -> Result<UpdateId>;

    /// Delete a relationship
    async fn delete_relationship(
        &mut self,
        source: &EntityId,
        target: &EntityId,
        relation_type: &str,
    ) -> Result<UpdateId>;

    /// Apply a batch of changes atomically
    async fn apply_delta(&mut self, delta: GraphDelta) -> Result<UpdateId>;

    /// Rollback a delta
    async fn rollback_delta(&mut self, delta_id: &UpdateId) -> Result<()>;

    /// Get change history
    async fn get_change_log(&self, since: Option<DateTime<Utc>>) -> Result<Vec<ChangeRecord>>;

    /// Start a transaction for atomic operations
    async fn begin_transaction(&mut self) -> Result<TransactionId>;

    /// Commit a transaction
    async fn commit_transaction(&mut self, tx_id: TransactionId) -> Result<()>;

    /// Rollback a transaction
    async fn rollback_transaction(&mut self, tx_id: TransactionId) -> Result<()>;

    /// Batch upsert entities with conflict resolution
    async fn batch_upsert_entities(
        &mut self,
        entities: Vec<Entity>,
        strategy: ConflictStrategy,
    ) -> Result<Vec<UpdateId>>;

    /// Batch upsert relationships with conflict resolution
    async fn batch_upsert_relationships(
        &mut self,
        relationships: Vec<Relationship>,
        strategy: ConflictStrategy,
    ) -> Result<Vec<UpdateId>>;

    /// Update entity embeddings incrementally
    async fn update_entity_embedding(
        &mut self,
        entity_id: &EntityId,
        embedding: Vec<f32>,
    ) -> Result<UpdateId>;

    /// Bulk update embeddings for performance
    async fn bulk_update_embeddings(
        &mut self,
        updates: Vec<(EntityId, Vec<f32>)>,
    ) -> Result<Vec<UpdateId>>;

    /// Get pending transactions
    async fn get_pending_transactions(&self) -> Result<Vec<TransactionId>>;

    /// Get graph statistics
    async fn get_graph_statistics(&self) -> Result<GraphStatistics>;

    /// Validate graph consistency
    async fn validate_consistency(&self) -> Result<ConsistencyReport>;
}

// ============================================================================
// Change Events
// ============================================================================

/// Change event for monitoring and debugging
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChangeEvent {
    /// Unique identifier for the event
    pub event_id: UpdateId,
    /// Type of change event
    pub event_type: ChangeEventType,
    /// Optional entity ID associated with the event
    pub entity_id: Option<EntityId>,
    /// When the event occurred
    pub timestamp: DateTime<Utc>,
    /// Additional metadata about the event
    pub metadata: HashMap<String, String>,
}

/// Types of change events that can be published
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ChangeEventType {
    /// An entity was upserted
    EntityUpserted,
    /// An entity was deleted
    EntityDeleted,
    /// A relationship was upserted
    RelationshipUpserted,
    /// A relationship was deleted
    RelationshipDeleted,
    /// An embedding was updated
    EmbeddingUpdated,
    /// A transaction was started
    TransactionStarted,
    /// A transaction was committed
    TransactionCommitted,
    /// A transaction was rolled back
    TransactionRolledBack,
    /// A conflict was resolved
    ConflictResolved,
    /// Cache was invalidated
    CacheInvalidated,
    /// A batch was processed
    BatchProcessed,
}

// ============================================================================
// Transaction Types
// ============================================================================

/// Transaction state for ACID operations
#[derive(Debug, Clone)]
#[allow(dead_code)]
struct Transaction {
    id: TransactionId,
    changes: Vec<ChangeRecord>,
    status: TransactionStatus,
    created_at: DateTime<Utc>,
    isolation_level: IsolationLevel,
}

#[derive(Debug, Clone, PartialEq)]
#[allow(dead_code)]
enum TransactionStatus {
    Active,
    Preparing,
    Committed,
    Aborted,
}

#[derive(Debug, Clone)]
#[allow(dead_code)]
enum IsolationLevel {
    ReadUncommitted,
    ReadCommitted,
    RepeatableRead,
    Serializable,
}

// ============================================================================
// Error Extensions
// ============================================================================

impl GraphRAGError {
    /// Creates a conflict resolution error
    pub fn conflict_resolution(message: String) -> Self {
        GraphRAGError::GraphConstruction { message }
    }

    /// Creates an incremental update error
    pub fn incremental_update(message: String) -> Self {
        GraphRAGError::GraphConstruction { message }
    }
}

// ============================================================================
// Production Graph Store
// ============================================================================

/// Production implementation of IncrementalGraphStore with full ACID guarantees
#[cfg(feature = "incremental")]
#[allow(dead_code)]
pub struct ProductionGraphStore {
    graph: Arc<RwLock<KnowledgeGraph>>,
    transactions: DashMap<TransactionId, Transaction>,
    change_log: DashMap<UpdateId, ChangeRecord>,
    rollback_data: DashMap<UpdateId, RollbackData>,
    conflict_resolver: Arc<ConflictResolver>,
    cache_invalidation: Arc<SelectiveInvalidation>,
    monitor: Arc<UpdateMonitor>,
    batch_processor: Arc<BatchProcessor>,
    incremental_pagerank: Arc<IncrementalPageRank>,
    event_publisher: broadcast::Sender<ChangeEvent>,
    config: IncrementalConfig,
}

#[cfg(feature = "incremental")]
impl ProductionGraphStore {
    /// Creates a new production-grade graph store with full ACID guarantees
    pub fn new(
        graph: KnowledgeGraph,
        config: IncrementalConfig,
        conflict_resolver: ConflictResolver,
    ) -> Self {
        let (event_tx, _) = broadcast::channel(1000);

        Self {
            graph: Arc::new(RwLock::new(graph)),
            transactions: DashMap::new(),
            change_log: DashMap::new(),
            rollback_data: DashMap::new(),
            conflict_resolver: Arc::new(conflict_resolver),
            cache_invalidation: Arc::new(SelectiveInvalidation::new()),
            monitor: Arc::new(UpdateMonitor::new()),
            batch_processor: Arc::new(BatchProcessor::new(
                config.batch_size,
                Duration::from_millis(100),
                config.max_concurrent_operations,
            )),
            incremental_pagerank: Arc::new(IncrementalPageRank::new(0.85, 1e-6, 100)),
            event_publisher: event_tx,
            config,
        }
    }

    /// Subscribes to change events for monitoring
    pub fn subscribe_events(&self) -> broadcast::Receiver<ChangeEvent> {
        self.event_publisher.subscribe()
    }

    async fn publish_event(&self, event: ChangeEvent) {
        let _ = self.event_publisher.send(event);
    }

    fn create_change_record(
        &self,
        change_type: ChangeType,
        operation: Operation,
        change_data: ChangeData,
        entity_id: Option<EntityId>,
        document_id: Option<crate::core::DocumentId>,
    ) -> ChangeRecord {
        ChangeRecord {
            change_id: UpdateId::new(),
            timestamp: Utc::now(),
            change_type,
            entity_id,
            document_id,
            operation,
            data: change_data,
            metadata: HashMap::new(),
        }
    }

    async fn apply_change_with_conflict_resolution(
        &self,
        change: ChangeRecord,
    ) -> Result<UpdateId> {
        let operation_id = self.monitor.start_operation("apply_change");

        // Check for conflicts
        if let Some(conflict) = self.detect_conflict(&change)? {
            let resolution = self.conflict_resolver.resolve_conflict(&conflict).await?;

            // Apply resolved change
            let resolved_change = ChangeRecord {
                data: resolution.resolved_data,
                metadata: resolution.metadata,
                ..change
            };

            self.apply_change_internal(resolved_change).await?;

            // Publish conflict resolution event
            self.publish_event(ChangeEvent {
                event_id: UpdateId::new(),
                event_type: ChangeEventType::ConflictResolved,
                entity_id: conflict.existing_data.get_entity_id(),
                timestamp: Utc::now(),
                metadata: HashMap::new(),
            })
            .await;
        } else {
            self.apply_change_internal(change).await?;
        }

        self.monitor
            .complete_operation(&operation_id, true, None, 1, 0);
        Ok(operation_id)
    }

    async fn apply_change_with_strategy(
        &self,
        change: ChangeRecord,
        strategy: &ConflictStrategy,
    ) -> Result<UpdateId> {
        let operation_id = self.monitor.start_operation("apply_change_with_strategy");

        // Check for conflicts
        if let Some(conflict) = self.detect_conflict(&change)? {
            let resolution = self
                .conflict_resolver
                .resolve_conflict_with_strategy(&conflict, strategy)
                .await?;

            // Apply resolved change
            let resolved_change = ChangeRecord {
                data: resolution.resolved_data,
                metadata: resolution.metadata,
                ..change
            };

            self.apply_change_internal(resolved_change).await?;

            // Publish conflict resolution event
            self.publish_event(ChangeEvent {
                event_id: UpdateId::new(),
                event_type: ChangeEventType::ConflictResolved,
                entity_id: conflict.existing_data.get_entity_id(),
                timestamp: Utc::now(),
                metadata: HashMap::new(),
            })
            .await;
        } else {
            self.apply_change_internal(change).await?;
        }

        self.monitor
            .complete_operation(&operation_id, true, None, 1, 0);
        Ok(operation_id)
    }

    fn detect_conflict(&self, change: &ChangeRecord) -> Result<Option<Conflict>> {
        match &change.data {
            ChangeData::Entity(entity) => {
                let graph = self.graph.read();
                if let Some(existing) = graph.get_entity(&entity.id) {
                    if existing.name != entity.name || existing.entity_type != entity.entity_type {
                        return Ok(Some(Conflict {
                            conflict_id: UpdateId::new(),
                            conflict_type: ConflictType::EntityExists,
                            existing_data: ChangeData::Entity(existing.clone()),
                            new_data: change.data.clone(),
                            resolution: None,
                        }));
                    }
                }
            }
            ChangeData::Relationship(relationship) => {
                let graph = self.graph.read();
                for existing_rel in graph.get_all_relationships() {
                    if existing_rel.source == relationship.source
                        && existing_rel.target == relationship.target
                        && existing_rel.relation_type == relationship.relation_type
                    {
                        return Ok(Some(Conflict {
                            conflict_id: UpdateId::new(),
                            conflict_type: ConflictType::RelationshipExists,
                            existing_data: ChangeData::Relationship(existing_rel.clone()),
                            new_data: change.data.clone(),
                            resolution: None,
                        }));
                    }
                }
            }
            _ => {}
        }

        Ok(None)
    }

    async fn apply_change_internal(&self, change: ChangeRecord) -> Result<()> {
        let change_id = change.change_id.clone();

        // Create rollback data first
        let rollback_data = {
            let graph = self.graph.read();
            self.create_rollback_data(&change, &graph)?
        };

        self.rollback_data.insert(change_id.clone(), rollback_data);

        // Apply the change
        {
            let mut graph = self.graph.write();
            match &change.data {
                ChangeData::Entity(entity) => {
                    match change.operation {
                        Operation::Insert | Operation::Upsert => {
                            graph.add_entity(entity.clone())?;
                            self.incremental_pagerank.record_change(entity.id.clone());
                        }
                        Operation::Delete => {
                            // Remove entity and its relationships
                            // Implementation would go here
                        }
                        _ => {}
                    }
                }
                ChangeData::Relationship(relationship) => {
                    match change.operation {
                        Operation::Insert | Operation::Upsert => {
                            graph.add_relationship(relationship.clone())?;
                            self.incremental_pagerank
                                .record_change(relationship.source.clone());
                            self.incremental_pagerank
                                .record_change(relationship.target.clone());
                        }
                        Operation::Delete => {
                            // Remove relationship
                            // Implementation would go here
                        }
                        _ => {}
                    }
                }
                ChangeData::Embedding {
                    entity_id,
                    embedding,
                } => {
                    if let Some(entity) = graph.get_entity_mut(entity_id) {
                        entity.embedding = Some(embedding.clone());
                    }
                }
                _ => {}
            }
        }

        // Record change in log
        self.change_log.insert(change_id, change);

        Ok(())
    }

    fn create_rollback_data(
        &self,
        change: &ChangeRecord,
        graph: &KnowledgeGraph,
    ) -> Result<RollbackData> {
        let mut previous_entities = Vec::new();
        let mut previous_relationships = Vec::new();

        match &change.data {
            ChangeData::Entity(entity) => {
                if let Some(existing) = graph.get_entity(&entity.id) {
                    previous_entities.push(existing.clone());
                }
            }
            ChangeData::Relationship(relationship) => {
                // Store existing relationships that might be affected
                for rel in graph.get_all_relationships() {
                    if rel.source == relationship.source && rel.target == relationship.target {
                        previous_relationships.push(rel.clone());
                    }
                }
            }
            _ => {}
        }

        Ok(RollbackData {
            previous_entities,
            previous_relationships,
            affected_caches: vec![], // Will be populated by cache invalidation system
        })
    }
}

#[cfg(feature = "incremental")]
#[async_trait::async_trait]
impl IncrementalGraphStore for ProductionGraphStore {
    type Error = GraphRAGError;

    async fn upsert_entity(&mut self, entity: Entity) -> Result<UpdateId> {
        let change = self.create_change_record(
            ChangeType::EntityAdded,
            Operation::Upsert,
            ChangeData::Entity(entity.clone()),
            Some(entity.id.clone()),
            None,
        );

        let update_id = self.apply_change_with_conflict_resolution(change).await?;

        // Trigger cache invalidation
        let changes = vec![self.change_log.get(&update_id).unwrap().clone()];
        let _invalidation_strategies = self.cache_invalidation.invalidate_for_changes(&changes);

        // Publish event
        self.publish_event(ChangeEvent {
            event_id: UpdateId::new(),
            event_type: ChangeEventType::EntityUpserted,
            entity_id: Some(entity.id),
            timestamp: Utc::now(),
            metadata: HashMap::new(),
        })
        .await;

        Ok(update_id)
    }

    async fn upsert_relationship(&mut self, relationship: Relationship) -> Result<UpdateId> {
        let change = self.create_change_record(
            ChangeType::RelationshipAdded,
            Operation::Upsert,
            ChangeData::Relationship(relationship.clone()),
            None,
            None,
        );

        let update_id = self.apply_change_with_conflict_resolution(change).await?;

        // Publish event
        self.publish_event(ChangeEvent {
            event_id: UpdateId::new(),
            event_type: ChangeEventType::RelationshipUpserted,
            entity_id: Some(relationship.source),
            timestamp: Utc::now(),
            metadata: HashMap::new(),
        })
        .await;

        Ok(update_id)
    }

    async fn delete_entity(&mut self, entity_id: &EntityId) -> Result<UpdateId> {
        let update_id = UpdateId::new();

        // Publish event
        self.publish_event(ChangeEvent {
            event_id: UpdateId::new(),
            event_type: ChangeEventType::EntityDeleted,
            entity_id: Some(entity_id.clone()),
            timestamp: Utc::now(),
            metadata: HashMap::new(),
        })
        .await;

        Ok(update_id)
    }

    async fn delete_relationship(
        &mut self,
        source: &EntityId,
        _target: &EntityId,
        _relation_type: &str,
    ) -> Result<UpdateId> {
        let update_id = UpdateId::new();

        // Publish event
        self.publish_event(ChangeEvent {
            event_id: UpdateId::new(),
            event_type: ChangeEventType::RelationshipDeleted,
            entity_id: Some(source.clone()),
            timestamp: Utc::now(),
            metadata: HashMap::new(),
        })
        .await;

        Ok(update_id)
    }

    async fn apply_delta(&mut self, delta: GraphDelta) -> Result<UpdateId> {
        let tx_id = self.begin_transaction().await?;

        for change in delta.changes {
            self.apply_change_with_conflict_resolution(change).await?;
        }

        self.commit_transaction(tx_id).await?;
        Ok(delta.delta_id)
    }

    async fn rollback_delta(&mut self, _delta_id: &UpdateId) -> Result<()> {
        // Implementation for delta rollback
        Ok(())
    }

    async fn get_change_log(&self, since: Option<DateTime<Utc>>) -> Result<Vec<ChangeRecord>> {
        let changes: Vec<ChangeRecord> = self
            .change_log
            .iter()
            .filter_map(|entry| {
                let change = entry.value();
                if let Some(since_time) = since {
                    if change.timestamp >= since_time {
                        Some(change.clone())
                    } else {
                        None
                    }
                } else {
                    Some(change.clone())
                }
            })
            .collect();

        Ok(changes)
    }

    async fn begin_transaction(&mut self) -> Result<TransactionId> {
        let tx_id = TransactionId::new();
        let transaction = Transaction {
            id: tx_id.clone(),
            changes: Vec::new(),
            status: TransactionStatus::Active,
            created_at: Utc::now(),
            isolation_level: IsolationLevel::ReadCommitted,
        };

        self.transactions.insert(tx_id.clone(), transaction);

        // Publish event
        self.publish_event(ChangeEvent {
            event_id: UpdateId::new(),
            event_type: ChangeEventType::TransactionStarted,
            entity_id: None,
            timestamp: Utc::now(),
            metadata: [("transaction_id".to_string(), tx_id.to_string())]
                .into_iter()
                .collect(),
        })
        .await;

        Ok(tx_id)
    }

    async fn commit_transaction(&mut self, tx_id: TransactionId) -> Result<()> {
        if let Some((_, mut tx)) = self.transactions.remove(&tx_id) {
            tx.status = TransactionStatus::Committed;

            // Publish event
            self.publish_event(ChangeEvent {
                event_id: UpdateId::new(),
                event_type: ChangeEventType::TransactionCommitted,
                entity_id: None,
                timestamp: Utc::now(),
                metadata: [("transaction_id".to_string(), tx_id.to_string())]
                    .into_iter()
                    .collect(),
            })
            .await;

            Ok(())
        } else {
            Err(GraphRAGError::IncrementalUpdate {
                message: format!("Transaction {tx_id} not found"),
            })
        }
    }

    async fn rollback_transaction(&mut self, tx_id: TransactionId) -> Result<()> {
        if let Some((_, mut tx)) = self.transactions.remove(&tx_id) {
            tx.status = TransactionStatus::Aborted;

            // Rollback all changes in this transaction
            for _change in &tx.changes {
                // Implementation for rollback
            }

            // Publish event
            self.publish_event(ChangeEvent {
                event_id: UpdateId::new(),
                event_type: ChangeEventType::TransactionRolledBack,
                entity_id: None,
                timestamp: Utc::now(),
                metadata: [("transaction_id".to_string(), tx_id.to_string())]
                    .into_iter()
                    .collect(),
            })
            .await;

            Ok(())
        } else {
            Err(GraphRAGError::IncrementalUpdate {
                message: format!("Transaction {tx_id} not found"),
            })
        }
    }

    async fn batch_upsert_entities(
        &mut self,
        entities: Vec<Entity>,
        strategy: ConflictStrategy,
    ) -> Result<Vec<UpdateId>> {
        if entities.is_empty() {
            return Ok(Vec::new());
        }

        let mut update_ids = Vec::with_capacity(entities.len());
        let mut all_changes = Vec::with_capacity(entities.len());
        let mut entity_ids = Vec::with_capacity(entities.len());

        // Apply all changes with the specified strategy
        for entity in entities {
            let entity_id = entity.id.clone();
            let change = self.create_change_record(
                ChangeType::EntityAdded,
                Operation::Upsert,
                ChangeData::Entity(entity),
                Some(entity_id.clone()),
                None,
            );

            let update_id = self.apply_change_with_strategy(change, &strategy).await?;

            // Collect the change for batch cache invalidation
            if let Some(change_record) = self.change_log.get(&update_id) {
                all_changes.push(change_record.clone());
            }

            update_ids.push(update_id);
            entity_ids.push(entity_id);
        }

        // Batch cache invalidation - single call for all changes
        if !all_changes.is_empty() {
            let _invalidation_strategies =
                self.cache_invalidation.invalidate_for_changes(&all_changes);
        }

        // Batch event publishing
        for entity_id in entity_ids {
            self.publish_event(ChangeEvent {
                event_id: UpdateId::new(),
                event_type: ChangeEventType::EntityUpserted,
                entity_id: Some(entity_id),
                timestamp: Utc::now(),
                metadata: HashMap::new(),
            })
            .await;
        }

        Ok(update_ids)
    }

    async fn batch_upsert_relationships(
        &mut self,
        relationships: Vec<Relationship>,
        strategy: ConflictStrategy,
    ) -> Result<Vec<UpdateId>> {
        if relationships.is_empty() {
            return Ok(Vec::new());
        }

        let mut update_ids = Vec::with_capacity(relationships.len());
        let mut all_changes = Vec::with_capacity(relationships.len());

        // Apply all changes with the specified strategy
        for relationship in relationships {
            let change = self.create_change_record(
                ChangeType::RelationshipAdded,
                Operation::Upsert,
                ChangeData::Relationship(relationship),
                None,
                None,
            );

            let update_id = self.apply_change_with_strategy(change, &strategy).await?;

            // Collect the change for batch cache invalidation
            if let Some(change_record) = self.change_log.get(&update_id) {
                all_changes.push(change_record.clone());
            }

            update_ids.push(update_id);
        }

        // Batch cache invalidation - single call for all changes
        if !all_changes.is_empty() {
            let _invalidation_strategies =
                self.cache_invalidation.invalidate_for_changes(&all_changes);
        }

        // Batch event publishing
        for update_id in &update_ids {
            self.publish_event(ChangeEvent {
                event_id: UpdateId::new(),
                event_type: ChangeEventType::RelationshipUpserted,
                entity_id: None,
                timestamp: Utc::now(),
                metadata: [("update_id".to_string(), update_id.to_string())]
                    .into_iter()
                    .collect(),
            })
            .await;
        }

        Ok(update_ids)
    }

    async fn update_entity_embedding(
        &mut self,
        entity_id: &EntityId,
        embedding: Vec<f32>,
    ) -> Result<UpdateId> {
        let change = self.create_change_record(
            ChangeType::EmbeddingUpdated,
            Operation::Update,
            ChangeData::Embedding {
                entity_id: entity_id.clone(),
                embedding,
            },
            Some(entity_id.clone()),
            None,
        );

        let update_id = self.apply_change_with_conflict_resolution(change).await?;

        // Publish event
        self.publish_event(ChangeEvent {
            event_id: UpdateId::new(),
            event_type: ChangeEventType::EmbeddingUpdated,
            entity_id: Some(entity_id.clone()),
            timestamp: Utc::now(),
            metadata: HashMap::new(),
        })
        .await;

        Ok(update_id)
    }

    async fn bulk_update_embeddings(
        &mut self,
        updates: Vec<(EntityId, Vec<f32>)>,
    ) -> Result<Vec<UpdateId>> {
        let mut update_ids = Vec::new();

        for (entity_id, embedding) in updates {
            let update_id = self.update_entity_embedding(&entity_id, embedding).await?;
            update_ids.push(update_id);
        }

        Ok(update_ids)
    }

    async fn get_pending_transactions(&self) -> Result<Vec<TransactionId>> {
        let pending: Vec<TransactionId> = self
            .transactions
            .iter()
            .filter(|entry| entry.value().status == TransactionStatus::Active)
            .map(|entry| entry.key().clone())
            .collect();

        Ok(pending)
    }

    async fn get_graph_statistics(&self) -> Result<GraphStatistics> {
        let graph = self.graph.read();
        let entities: Vec<_> = graph.entities().collect();
        let relationships = graph.get_all_relationships();

        let node_count = entities.len();
        let edge_count = relationships.len();

        // Calculate average degree
        let total_degree: usize = entities
            .iter()
            .map(|entity| graph.get_neighbors(&entity.id).len())
            .sum();

        let average_degree = if node_count > 0 {
            total_degree as f64 / node_count as f64
        } else {
            0.0
        };

        // Find max degree
        let max_degree = entities
            .iter()
            .map(|entity| graph.get_neighbors(&entity.id).len())
            .max()
            .unwrap_or(0);

        Ok(GraphStatistics {
            node_count,
            edge_count,
            average_degree,
            max_degree,
            connected_components: 1,     // Simplified for now
            clustering_coefficient: 0.0, // Would need complex calculation
            last_updated: Utc::now(),
        })
    }

    async fn validate_consistency(&self) -> Result<ConsistencyReport> {
        let graph = self.graph.read();
        let mut orphaned_entities = Vec::new();
        let mut broken_relationships = Vec::new();
        let mut missing_embeddings = Vec::new();

        // Check for orphaned entities (entities with no relationships)
        for entity in graph.entities() {
            let neighbors = graph.get_neighbors(&entity.id);
            if neighbors.is_empty() {
                orphaned_entities.push(entity.id.clone());
            }

            // Check for missing embeddings
            if entity.embedding.is_none() {
                missing_embeddings.push(entity.id.clone());
            }
        }

        // Check for broken relationships (references to non-existent entities)
        for relationship in graph.get_all_relationships() {
            if graph.get_entity(&relationship.source).is_none()
                || graph.get_entity(&relationship.target).is_none()
            {
                broken_relationships.push((
                    relationship.source.clone(),
                    relationship.target.clone(),
                    relationship.relation_type.clone(),
                ));
            }
        }

        let issues_found =
            orphaned_entities.len() + broken_relationships.len() + missing_embeddings.len();

        Ok(ConsistencyReport {
            is_consistent: issues_found == 0,
            orphaned_entities,
            broken_relationships,
            missing_embeddings,
            validation_time: Utc::now(),
            issues_found,
        })
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[cfg(feature = "incremental")]
    #[tokio::test]
    async fn test_production_graph_store_creation() {
        let graph = KnowledgeGraph::new();
        let config = IncrementalConfig::default();
        let resolver = ConflictResolver::new(ConflictStrategy::Merge);
        let _store = ProductionGraphStore::new(graph, config, resolver);
    }

    #[test]
    fn test_graph_statistics_creation() {
        let stats = GraphStatistics {
            node_count: 100,
            edge_count: 500,
            average_degree: 5.0,
            max_degree: 25,
            connected_components: 3,
            clustering_coefficient: 0.45,
            last_updated: Utc::now(),
        };
        assert_eq!(stats.node_count, 100);
        assert_eq!(stats.edge_count, 500);
    }

    #[test]
    fn test_consistency_report_creation() {
        let report = ConsistencyReport {
            is_consistent: true,
            orphaned_entities: vec![],
            broken_relationships: vec![],
            missing_embeddings: vec![],
            validation_time: Utc::now(),
            issues_found: 0,
        };
        assert!(report.is_consistent);
        assert_eq!(report.issues_found, 0);
    }

    #[test]
    fn test_change_event_creation() {
        let event = ChangeEvent {
            event_id: UpdateId::new(),
            event_type: ChangeEventType::EntityUpserted,
            entity_id: Some(EntityId::new("test".to_string())),
            timestamp: Utc::now(),
            metadata: HashMap::new(),
        };
        assert!(matches!(event.event_type, ChangeEventType::EntityUpserted));
    }
}
